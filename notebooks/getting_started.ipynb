{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset\n",
    "If you want to run prompt optimization on your own dataset, follow these steps:\n",
    "\n",
    "1. Create a folder.\n",
    "1. Create a .txt file in the folder named \"prompts.txt\". It should contain 8-12 initial prompts from where you can start the optimization. Add line breaks between each of the prompts\n",
    "1. Create two .txt files in another folder, which contain the dev set \"dev.txt\" and test set \"test.txt\" of your data points. Convert the classes of your file into integers. \n",
    "Make sure to seperate the input from the expected output with a tab!\n",
    "1. Create a description.json file that contains a dictionary, specifying:\n",
    "    - \"seed\": the folder in which you find the dev and test files\n",
    "    - \"init_prompts\": the name of the .txt file pointing to the prompts\n",
    "    - \"description\": A short description of your task, that is fed to the meta-llm in order to optimize the prompts. \n",
    "    (TIP: Include \"The class mentioned first in the response of the LLM will be the prediction.\" in the description if this is how you evaluate the models responses)\n",
    "    - \"classes\": A list of the names of the classes you are trying to predict\n",
    "\n",
    "You can find examples of how this needs to be set up in our repo at data_sets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install promptolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptolution.helpers import run_experiment\n",
    "from promptolution.config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up llms, predictor, tasks and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = open(\"../deepinfratoken.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    task_name=\"agnews\",\n",
    "    ds_path=\"../data_sets/cls/agnews/\",\n",
    "    n_steps=8,\n",
    "    optimizer=\"evopromptde\",\n",
    "    meta_llm=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    evaluation_llm=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    downstream_llm=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    api_token=token,\n",
    "    prepend_exemplars=True,\n",
    "    exemplar_selector=\"random_search\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_experiment(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You will be required to classify a news articl...</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Categorize the news article into one of four c...</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your task is to identify the primary topic of ...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Based on the main theme of given the news arti...</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classify the topic of the following news as \"W...</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  score\n",
       "3  You will be required to classify a news articl...   0.70\n",
       "2  Categorize the news article into one of four c...   0.58\n",
       "4  Your task is to identify the primary topic of ...   0.50\n",
       "1  Based on the main theme of given the news arti...   0.36\n",
       "0  Classify the topic of the following news as \"W...   0.30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
